{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **How to use the Modelmaker for predicting the correct fish species.**"
      ],
      "metadata": {
        "id": "HuHXDvChhs7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install all requirements and connect with your data from Google Drive"
      ],
      "metadata": {
        "id": "of039y30g_0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q tflite-model-maker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EvZT8DVl8Y-",
        "outputId": "05f7709f-7bbf-48ae-c042-09fea1210713"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 KB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.6/128.6 KB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.0/498.0 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 KB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.4/222.4 KB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2022.12.0 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import image_classifier\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker.config import QuantizationConfig\n",
        "from tflite_model_maker.image_classifier import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EIDCX_peFmq",
        "outputId": "b6fedfb9-82bf-44fb-9169-b0c4d430c93e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.8.4 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "PA8FpBnIeXKs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBmF7Lw0f_k6",
        "outputId": "b6522280-d555-4859-f48b-5b860eb43f6d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PD9rrXzOLpkZ"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "from pathlib import Path\n",
        "data_dir = Path(\"/content/drive/MyDrive/fish_photos/families\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data and split it into train and test data"
      ],
      "metadata": {
        "id": "jTf7PWoqh-TN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = DataLoader.from_folder(\"/content/drive/MyDrive/fish_photos/families\")\n",
        "train_data, test_data = data.split(0.9)\n"
      ],
      "metadata": {
        "id": "ZGDH49MIgS40"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model. The following parameters will lead to the best results"
      ],
      "metadata": {
        "id": "yWsEVIkHiFys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = image_classifier.create(train_data, epochs=30, use_augmentation=True, dropout_rate=0.2, shuffle=True )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIUIRwcGiOOk",
        "outputId": "90d25dd9-d7ff-415a-c9d2-5c4571ce6888"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hub_keras_layer_v1v2 (HubKe  (None, 1280)             11837936  \n",
            " rasLayerV1V2)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 193)               247233    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,085,169\n",
            "Trainable params: 247,233\n",
            "Non-trainable params: 11,837,936\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "124/124 [==============================] - 400s 3s/step - loss: 4.6105 - accuracy: 0.1406\n",
            "Epoch 2/30\n",
            "124/124 [==============================] - 37s 287ms/step - loss: 4.1420 - accuracy: 0.2069\n",
            "Epoch 3/30\n",
            "124/124 [==============================] - 37s 288ms/step - loss: 3.9388 - accuracy: 0.2447\n",
            "Epoch 4/30\n",
            "124/124 [==============================] - 37s 292ms/step - loss: 3.7748 - accuracy: 0.2608\n",
            "Epoch 5/30\n",
            "124/124 [==============================] - 37s 294ms/step - loss: 3.6798 - accuracy: 0.2928\n",
            "Epoch 6/30\n",
            "124/124 [==============================] - 37s 291ms/step - loss: 3.5620 - accuracy: 0.3034\n",
            "Epoch 7/30\n",
            "124/124 [==============================] - 37s 292ms/step - loss: 3.4668 - accuracy: 0.3299\n",
            "Epoch 8/30\n",
            "124/124 [==============================] - 37s 291ms/step - loss: 3.4038 - accuracy: 0.3357\n",
            "Epoch 9/30\n",
            "124/124 [==============================] - 41s 323ms/step - loss: 3.3542 - accuracy: 0.3415\n",
            "Epoch 10/30\n",
            "124/124 [==============================] - 36s 282ms/step - loss: 3.3111 - accuracy: 0.3566\n",
            "Epoch 11/30\n",
            "124/124 [==============================] - 36s 285ms/step - loss: 3.2459 - accuracy: 0.3569\n",
            "Epoch 12/30\n",
            "124/124 [==============================] - 37s 283ms/step - loss: 3.1876 - accuracy: 0.3720\n",
            "Epoch 13/30\n",
            "124/124 [==============================] - 37s 290ms/step - loss: 3.1716 - accuracy: 0.3740\n",
            "Epoch 14/30\n",
            "124/124 [==============================] - 37s 291ms/step - loss: 3.1117 - accuracy: 0.3939\n",
            "Epoch 15/30\n",
            "124/124 [==============================] - 40s 315ms/step - loss: 3.1005 - accuracy: 0.3818\n",
            "Epoch 16/30\n",
            "124/124 [==============================] - 37s 288ms/step - loss: 3.0635 - accuracy: 0.4045\n",
            "Epoch 17/30\n",
            "124/124 [==============================] - 37s 291ms/step - loss: 3.0281 - accuracy: 0.4025\n",
            "Epoch 18/30\n",
            "124/124 [==============================] - 35s 277ms/step - loss: 3.0119 - accuracy: 0.4088\n",
            "Epoch 19/30\n",
            "124/124 [==============================] - 36s 284ms/step - loss: 2.9665 - accuracy: 0.4206\n",
            "Epoch 20/30\n",
            "124/124 [==============================] - 37s 282ms/step - loss: 2.9531 - accuracy: 0.4246\n",
            "Epoch 21/30\n",
            "124/124 [==============================] - 37s 289ms/step - loss: 2.9544 - accuracy: 0.4199\n",
            "Epoch 22/30\n",
            "124/124 [==============================] - 40s 320ms/step - loss: 2.9400 - accuracy: 0.4257\n",
            "Epoch 23/30\n",
            "124/124 [==============================] - 37s 292ms/step - loss: 2.8959 - accuracy: 0.4340\n",
            "Epoch 24/30\n",
            "124/124 [==============================] - 37s 292ms/step - loss: 2.8851 - accuracy: 0.4413\n",
            "Epoch 25/30\n",
            "124/124 [==============================] - 37s 295ms/step - loss: 2.8587 - accuracy: 0.4388\n",
            "Epoch 26/30\n",
            "124/124 [==============================] - 36s 283ms/step - loss: 2.8546 - accuracy: 0.4468\n",
            "Epoch 27/30\n",
            "124/124 [==============================] - 35s 273ms/step - loss: 2.8469 - accuracy: 0.4476\n",
            "Epoch 28/30\n",
            "124/124 [==============================] - 40s 318ms/step - loss: 2.8207 - accuracy: 0.4577\n",
            "Epoch 29/30\n",
            "124/124 [==============================] - 37s 290ms/step - loss: 2.7715 - accuracy: 0.4647\n",
            "Epoch 30/30\n",
            "124/124 [==============================] - 37s 292ms/step - loss: 2.7710 - accuracy: 0.4635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model!"
      ],
      "metadata": {
        "id": "jiw4E59miSPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Je-F5udGhDvM",
        "outputId": "8b84f455-ecfc-4ce7-c2fe-c92cbd265e38"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 63s 3s/step - loss: 2.7524 - accuracy: 0.4864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A helper function that returns 'red'/'black' depending on if its two input\n",
        "# parameter matches or not.\n",
        "def get_label_color(val1, val2):\n",
        "  if val1 == val2:\n",
        "    return 'black'\n",
        "  else:\n",
        "    return 'red'\n",
        "\n",
        "# Then plot 30 test images and their predicted labels.\n",
        "# If a prediction result is different from the label provided label in \"test\"\n",
        "# dataset, we will highlight it in red color.\n",
        "plt.figure(figsize=(40, 40))\n",
        "predicts = model.predict_top_k(test_data)\n",
        "for i, (image, label) in enumerate(test_data.gen_dataset().unbatch().take(50)):\n",
        "  ax = plt.subplot(10, 10, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image.numpy(), cmap=plt.cm.gray)\n",
        "\n",
        "  predict_label = predicts[i][0][0]\n",
        "  color = get_label_color(predict_label,\n",
        "                          test_data.index_to_label[label.numpy()])\n",
        "  ax.xaxis.label.set_color(color)\n",
        "  plt.xlabel('Predicted: %s' % predict_label)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "a5aUf2XBhmIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, save the model to use it later."
      ],
      "metadata": {
        "id": "NUiIjeZbiiig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_dir = \"/content/drive/MyDrive/fish_photos/model\"\n",
        "model.export(export_dir=model_save_dir, export_format= ExportFormat.TFLITE,saved_model_filename = 'familymodel')"
      ],
      "metadata": {
        "id": "9uZphivIV6hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_dir = \"/content/drive/MyDrive/fish_photos/model\"\n",
        "model.export(export_dir=model_save_dir, export_format = ExportFormat.SAVED_MODEL, saved_model_filename = 'familymodel')"
      ],
      "metadata": {
        "id": "E5dXKm9gmOWy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}